{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_csv('./data/twitter_accounts.csv')\n",
    "languages = words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aus_der_UBahn</td>\n",
       "      <td>lemondefr</td>\n",
       "      <td>Pontifex_it</td>\n",
       "      <td>bbcmundo</td>\n",
       "      <td>HiddenBrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mainwasser</td>\n",
       "      <td>ouimenon</td>\n",
       "      <td>repubblica</td>\n",
       "      <td>CNNEE</td>\n",
       "      <td>LinusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrumpyMerkel</td>\n",
       "      <td>SemounElie</td>\n",
       "      <td>Corriere</td>\n",
       "      <td>platzi</td>\n",
       "      <td>lexfridman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPIEGEL_alles</td>\n",
       "      <td>MonsieurDream</td>\n",
       "      <td>StefaniaChiale</td>\n",
       "      <td>perezreverte</td>\n",
       "      <td>hubermanlab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dw_deutsch</td>\n",
       "      <td>valtrier</td>\n",
       "      <td>sferaebbasta</td>\n",
       "      <td>Statista_ES</td>\n",
       "      <td>davidasinclair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          German         French         Italian       Spanish         English\n",
       "0  Aus_der_UBahn      lemondefr     Pontifex_it      bbcmundo     HiddenBrain\n",
       "1     mainwasser       ouimenon      repubblica         CNNEE       LinusTech\n",
       "2   GrumpyMerkel     SemounElie        Corriere        platzi      lexfridman\n",
       "3  SPIEGEL_alles  MonsieurDream  StefaniaChiale  perezreverte     hubermanlab\n",
       "4     dw_deutsch       valtrier    sferaebbasta   Statista_ES  davidasinclair"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key    = 'RSAGjcysielA9Bf6c5EWtsGLG'\n",
    "consumer_secret = 'aT4PO4g1b8yd3cGeJOSuyc1M1xSh6U4UR7FIOZoTG3BMrizpMW'\n",
    "\n",
    "access_token    = '1195625971065294848-IYELbxVk72dpIhsEgdYSupES41x3b2'\n",
    "access_secret   = 'Nv9MDblwhSHrMeDKhomdzyrY9L4AfUeNvXtkttmXhYS23'\n",
    "\n",
    "callback_uri = 'oob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to Take\n",
    "- Get *x* number of tweets using the `count` parameter\n",
    "- Result is a list of json files containing data about each tweet\n",
    "- Search for just the text data using `text` attribute\n",
    "- Append the data to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example\n",
    "# first_user = api.user_timeline(screen_name = first, count=5)\n",
    "# user = first_user[4]\n",
    "# user.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets to collect per user\n",
    "tweet_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(username):\n",
    "    text_data = []\n",
    "    tweet_data = api.user_timeline(screen_name=username, count=tweet_num, tweet_mode='extended')\n",
    "    \n",
    "    # Get the text from the tweet\n",
    "    for tweet in tweet_data:\n",
    "        text_data.append(tweet.full_text)\n",
    "\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df = pd.DataFrame()  # Empty DataFrame to hold tweets\n",
    "\n",
    "for language in languages:\n",
    "    usernames = words_df[language].copy()  # List of usernames\n",
    "    full_tweets = []  # Empty list to hold tweets\n",
    "\n",
    "    # Iterate over usernames and get the tweet\n",
    "    for username in usernames:\n",
    "        full_tweets.extend(get_text(username=username))\n",
    "    \n",
    "    # Create DataFrame containing text data\n",
    "    lang_df = pd.DataFrame(data=full_tweets, columns=[f'{language}'])\n",
    "\n",
    "    language_df = pd.concat([language_df, lang_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeehrChaos @neSeemannsbraut Naja, ich war ger...</td>\n",
       "      <td>Un dÃ©but dâ€™accalmie sur le front des incendies...</td>\n",
       "      <td>Siamo al mondo per vivere una storia dâ€™amore c...</td>\n",
       "      <td>Cuando el escritor estaba en el escenario, el ...</td>\n",
       "      <td>Weâ€™re told not to dwell on the past, but is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@FrauZimt â€žIch finde, in der Stadt hÃ¤lt man da...</td>\n",
       "      <td>Etats-Unis : le plan climat et santÃ© de Joe Bi...</td>\n",
       "      <td>Chi si crede ricco, vincente e sicuro, fonda t...</td>\n",
       "      <td>El caso de Lee reafirma la concepciÃ³n popular ...</td>\n",
       "      <td>Despite our intuition, Wilson says we're not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â€žAch, diese Hitzewellen, dieser Klimawandel, s...</td>\n",
       "      <td>MarchÃ©s dâ€™Europe, Stevenson, luttes fÃ©ministes...</td>\n",
       "      <td>La vecchiaia Ã¨ la fase della vita piÃ¹ adatta a...</td>\n",
       "      <td>La orden de registro al hogar del expresidente...</td>\n",
       "      <td>The results? The women who saw the profile wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@regenmuseum Harte, Ã¤h, trockene Zeitenâ€¦ ðŸ˜¢</td>\n",
       "      <td>Comment Ginko Financial, la plus cÃ©lÃ¨bre banqu...</td>\n",
       "      <td>Quanto Ã¨ prezioso quel senso di familiaritÃ  e ...</td>\n",
       "      <td>La novela \"Los versos satÃ¡nicos\", de Salman Ru...</td>\n",
       "      <td>How well do you know yourself?\\n\\nIn a speed d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rainerklute ðŸ’¡</td>\n",
       "      <td>Lâ€™actrice amÃ©ricaine Anne Heche dÃ©clarÃ©e morte...</td>\n",
       "      <td>La rinascita di un dialogo passa non dalle par...</td>\n",
       "      <td>En Corea del Sur, los conglomerados gigantes d...</td>\n",
       "      <td>\"I feel like she's a guardian angel of my subc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              German  \\\n",
       "0  @MeehrChaos @neSeemannsbraut Naja, ich war ger...   \n",
       "1  @FrauZimt â€žIch finde, in der Stadt hÃ¤lt man da...   \n",
       "2  â€žAch, diese Hitzewellen, dieser Klimawandel, s...   \n",
       "3         @regenmuseum Harte, Ã¤h, trockene Zeitenâ€¦ ðŸ˜¢   \n",
       "4                                     @rainerklute ðŸ’¡   \n",
       "\n",
       "                                              French  \\\n",
       "0  Un dÃ©but dâ€™accalmie sur le front des incendies...   \n",
       "1  Etats-Unis : le plan climat et santÃ© de Joe Bi...   \n",
       "2  MarchÃ©s dâ€™Europe, Stevenson, luttes fÃ©ministes...   \n",
       "3  Comment Ginko Financial, la plus cÃ©lÃ¨bre banqu...   \n",
       "4  Lâ€™actrice amÃ©ricaine Anne Heche dÃ©clarÃ©e morte...   \n",
       "\n",
       "                                             Italian  \\\n",
       "0  Siamo al mondo per vivere una storia dâ€™amore c...   \n",
       "1  Chi si crede ricco, vincente e sicuro, fonda t...   \n",
       "2  La vecchiaia Ã¨ la fase della vita piÃ¹ adatta a...   \n",
       "3  Quanto Ã¨ prezioso quel senso di familiaritÃ  e ...   \n",
       "4  La rinascita di un dialogo passa non dalle par...   \n",
       "\n",
       "                                             Spanish  \\\n",
       "0  Cuando el escritor estaba en el escenario, el ...   \n",
       "1  El caso de Lee reafirma la concepciÃ³n popular ...   \n",
       "2  La orden de registro al hogar del expresidente...   \n",
       "3  La novela \"Los versos satÃ¡nicos\", de Salman Ru...   \n",
       "4  En Corea del Sur, los conglomerados gigantes d...   \n",
       "\n",
       "                                             English  \n",
       "0  Weâ€™re told not to dwell on the past, but is no...  \n",
       "1  Despite our intuition, Wilson says we're not a...  \n",
       "2  The results? The women who saw the profile wer...  \n",
       "3  How well do you know yourself?\\n\\nIn a speed d...  \n",
       "4  \"I feel like she's a guardian angel of my subc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the DataFrame as a *csv* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df.to_csv('./data/raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
