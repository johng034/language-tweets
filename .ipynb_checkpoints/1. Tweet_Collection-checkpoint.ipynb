{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_csv('./data/twitter_accounts.csv')\n",
    "languages = words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aus_der_UBahn</td>\n",
       "      <td>lemondefr</td>\n",
       "      <td>Pontifex_it</td>\n",
       "      <td>bbcmundo</td>\n",
       "      <td>HiddenBrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mainwasser</td>\n",
       "      <td>ouimenon</td>\n",
       "      <td>repubblica</td>\n",
       "      <td>CNNEE</td>\n",
       "      <td>LinusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GrumpyMerkel</td>\n",
       "      <td>SemounElie</td>\n",
       "      <td>Corriere</td>\n",
       "      <td>platzi</td>\n",
       "      <td>lexfridman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPIEGEL_alles</td>\n",
       "      <td>MonsieurDream</td>\n",
       "      <td>StefaniaChiale</td>\n",
       "      <td>perezreverte</td>\n",
       "      <td>hubermanlab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dw_deutsch</td>\n",
       "      <td>valtrier</td>\n",
       "      <td>sferaebbasta</td>\n",
       "      <td>Statista_ES</td>\n",
       "      <td>davidasinclair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          German         French         Italian       Spanish         English\n",
       "0  Aus_der_UBahn      lemondefr     Pontifex_it      bbcmundo     HiddenBrain\n",
       "1     mainwasser       ouimenon      repubblica         CNNEE       LinusTech\n",
       "2   GrumpyMerkel     SemounElie        Corriere        platzi      lexfridman\n",
       "3  SPIEGEL_alles  MonsieurDream  StefaniaChiale  perezreverte     hubermanlab\n",
       "4     dw_deutsch       valtrier    sferaebbasta   Statista_ES  davidasinclair"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key    = 'RSAGjcysielA9Bf6c5EWtsGLG'\n",
    "consumer_secret = 'aT4PO4g1b8yd3cGeJOSuyc1M1xSh6U4UR7FIOZoTG3BMrizpMW'\n",
    "\n",
    "access_token    = '1195625971065294848-IYELbxVk72dpIhsEgdYSupES41x3b2'\n",
    "access_secret   = 'Nv9MDblwhSHrMeDKhomdzyrY9L4AfUeNvXtkttmXhYS23'\n",
    "\n",
    "callback_uri = 'oob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to Take\n",
    "- Get *x* number of tweets using the `count` parameter\n",
    "- Result is a list of json files containing data about each tweet\n",
    "- Search for just the text data using `text` attribute\n",
    "- Append the data to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example\n",
    "# first_user = api.user_timeline(screen_name = first, count=5)\n",
    "# user = first_user[4]\n",
    "# user.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets to collect per user\n",
    "tweet_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(username):\n",
    "    text_data = []\n",
    "    tweet_data = api.user_timeline(screen_name=username, count=tweet_num, tweet_mode='extended')\n",
    "    \n",
    "    # Get the text from the tweet\n",
    "    for tweet in tweet_data:\n",
    "        text_data.append(tweet.full_text)\n",
    "\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df = pd.DataFrame()  # Empty DataFrame to hold tweets\n",
    "\n",
    "for language in languages:\n",
    "    usernames = words_df[language].copy()  # List of usernames\n",
    "    full_tweets = []  # Empty list to hold tweets\n",
    "\n",
    "    # Iterate over usernames and get the tweet\n",
    "    for username in usernames:\n",
    "        full_tweets.extend(get_text(username=username))\n",
    "    \n",
    "    # Create DataFrame containing text data\n",
    "    lang_df = pd.DataFrame(data=full_tweets, columns=[f'{language}'])\n",
    "\n",
    "    language_df = pd.concat([language_df, lang_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeehrChaos @neSeemannsbraut Naja, ich war ger...</td>\n",
       "      <td>Un d√©but d‚Äôaccalmie sur le front des incendies...</td>\n",
       "      <td>Siamo al mondo per vivere una storia d‚Äôamore c...</td>\n",
       "      <td>Cuando el escritor estaba en el escenario, el ...</td>\n",
       "      <td>We‚Äôre told not to dwell on the past, but is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@FrauZimt ‚ÄûIch finde, in der Stadt h√§lt man da...</td>\n",
       "      <td>Etats-Unis : le plan climat et sant√© de Joe Bi...</td>\n",
       "      <td>Chi si crede ricco, vincente e sicuro, fonda t...</td>\n",
       "      <td>El caso de Lee reafirma la concepci√≥n popular ...</td>\n",
       "      <td>Despite our intuition, Wilson says we're not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ÄûAch, diese Hitzewellen, dieser Klimawandel, s...</td>\n",
       "      <td>March√©s d‚ÄôEurope, Stevenson, luttes f√©ministes...</td>\n",
       "      <td>La vecchiaia √® la fase della vita pi√π adatta a...</td>\n",
       "      <td>La orden de registro al hogar del expresidente...</td>\n",
       "      <td>The results? The women who saw the profile wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@regenmuseum Harte, √§h, trockene Zeiten‚Ä¶ üò¢</td>\n",
       "      <td>Comment Ginko Financial, la plus c√©l√®bre banqu...</td>\n",
       "      <td>Quanto √® prezioso quel senso di familiarit√† e ...</td>\n",
       "      <td>La novela \"Los versos sat√°nicos\", de Salman Ru...</td>\n",
       "      <td>How well do you know yourself?\\n\\nIn a speed d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rainerklute üí°</td>\n",
       "      <td>L‚Äôactrice am√©ricaine Anne Heche d√©clar√©e morte...</td>\n",
       "      <td>La rinascita di un dialogo passa non dalle par...</td>\n",
       "      <td>En Corea del Sur, los conglomerados gigantes d...</td>\n",
       "      <td>\"I feel like she's a guardian angel of my subc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              German  \\\n",
       "0  @MeehrChaos @neSeemannsbraut Naja, ich war ger...   \n",
       "1  @FrauZimt ‚ÄûIch finde, in der Stadt h√§lt man da...   \n",
       "2  ‚ÄûAch, diese Hitzewellen, dieser Klimawandel, s...   \n",
       "3         @regenmuseum Harte, √§h, trockene Zeiten‚Ä¶ üò¢   \n",
       "4                                     @rainerklute üí°   \n",
       "\n",
       "                                              French  \\\n",
       "0  Un d√©but d‚Äôaccalmie sur le front des incendies...   \n",
       "1  Etats-Unis : le plan climat et sant√© de Joe Bi...   \n",
       "2  March√©s d‚ÄôEurope, Stevenson, luttes f√©ministes...   \n",
       "3  Comment Ginko Financial, la plus c√©l√®bre banqu...   \n",
       "4  L‚Äôactrice am√©ricaine Anne Heche d√©clar√©e morte...   \n",
       "\n",
       "                                             Italian  \\\n",
       "0  Siamo al mondo per vivere una storia d‚Äôamore c...   \n",
       "1  Chi si crede ricco, vincente e sicuro, fonda t...   \n",
       "2  La vecchiaia √® la fase della vita pi√π adatta a...   \n",
       "3  Quanto √® prezioso quel senso di familiarit√† e ...   \n",
       "4  La rinascita di un dialogo passa non dalle par...   \n",
       "\n",
       "                                             Spanish  \\\n",
       "0  Cuando el escritor estaba en el escenario, el ...   \n",
       "1  El caso de Lee reafirma la concepci√≥n popular ...   \n",
       "2  La orden de registro al hogar del expresidente...   \n",
       "3  La novela \"Los versos sat√°nicos\", de Salman Ru...   \n",
       "4  En Corea del Sur, los conglomerados gigantes d...   \n",
       "\n",
       "                                             English  \n",
       "0  We‚Äôre told not to dwell on the past, but is no...  \n",
       "1  Despite our intuition, Wilson says we're not a...  \n",
       "2  The results? The women who saw the profile wer...  \n",
       "3  How well do you know yourself?\\n\\nIn a speed d...  \n",
       "4  \"I feel like she's a guardian angel of my subc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the DataFrame as a *csv* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_df.to_csv('./data/raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
