{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_data.csv')\n",
    "languages = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naja gerade frankreich tatsächlich schrecklich...</td>\n",
       "      <td>début accalmie front incendies france</td>\n",
       "      <td>mondo vivere storia d amore dio abbracciare au...</td>\n",
       "      <td>escritor escenario agresor subi tarima asest r...</td>\n",
       "      <td>told dwell past nostalgia exception weekly new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finde stadt hält gar fahre abends immer kurz w...</td>\n",
       "      <td>etats unis plan climat santé joe biden adopté ...</td>\n",
       "      <td>crede ricco vincente sicuro fonda sé chiude di...</td>\n",
       "      <td>caso lee reafirma concepci n popular l deres e...</td>\n",
       "      <td>despite intuition wilson says actually good pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ach hitzewellen klimawandel schlimm gleich mal...</td>\n",
       "      <td>marchés europe stevenson luttes féministes rep...</td>\n",
       "      <td>vecchiaia fase vita adatta diffondere lieta no...</td>\n",
       "      <td>orden registro hogar expresidente expone trump...</td>\n",
       "      <td>results women saw profile poor predicting eith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harte äh trockene zeiten</td>\n",
       "      <td>comment ginko financial plus célèbre banque se...</td>\n",
       "      <td>prezioso quel senso familiarità comunità tanto...</td>\n",
       "      <td>novela versos sat nicos salman rushdie conside...</td>\n",
       "      <td>well know speed dating study women rated much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>actrice américaine anne heche déclarée morte s...</td>\n",
       "      <td>rinascita dialogo passa parole silenzio impunt...</td>\n",
       "      <td>corea sur conglomerados gigantes dominan econo...</td>\n",
       "      <td>feel like guardian angel subconscious remind c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              German  \\\n",
       "0  naja gerade frankreich tatsächlich schrecklich...   \n",
       "1  finde stadt hält gar fahre abends immer kurz w...   \n",
       "2  ach hitzewellen klimawandel schlimm gleich mal...   \n",
       "3                           harte äh trockene zeiten   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              French  \\\n",
       "0              début accalmie front incendies france   \n",
       "1  etats unis plan climat santé joe biden adopté ...   \n",
       "2  marchés europe stevenson luttes féministes rep...   \n",
       "3  comment ginko financial plus célèbre banque se...   \n",
       "4  actrice américaine anne heche déclarée morte s...   \n",
       "\n",
       "                                             Italian  \\\n",
       "0  mondo vivere storia d amore dio abbracciare au...   \n",
       "1  crede ricco vincente sicuro fonda sé chiude di...   \n",
       "2  vecchiaia fase vita adatta diffondere lieta no...   \n",
       "3  prezioso quel senso familiarità comunità tanto...   \n",
       "4  rinascita dialogo passa parole silenzio impunt...   \n",
       "\n",
       "                                             Spanish  \\\n",
       "0  escritor escenario agresor subi tarima asest r...   \n",
       "1  caso lee reafirma concepci n popular l deres e...   \n",
       "2  orden registro hogar expresidente expone trump...   \n",
       "3  novela versos sat nicos salman rushdie conside...   \n",
       "4  corea sur conglomerados gigantes dominan econo...   \n",
       "\n",
       "                                             English  \n",
       "0  told dwell past nostalgia exception weekly new...  \n",
       "1  despite intuition wilson says actually good pr...  \n",
       "2  results women saw profile poor predicting eith...  \n",
       "3  well know speed dating study women rated much ...  \n",
       "4  feel like guardian angel subconscious remind c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_rows(df, language):\n",
    "    series = df[language]\n",
    "\n",
    "    # Get the index of any empty rows\n",
    "    empty_rows = df[(df[language] == '') | (df[language].isna())].index\n",
    "    \n",
    "    # Drop those rows using the index\n",
    "    empty_removed = series.drop(empty_rows, axis=0)\n",
    "\n",
    "    # Reset the index\n",
    "    empty_removed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return empty_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_paths = {\n",
    "    'German' : './wordclouds/german_wordcloud.png',\n",
    "    'French' : './wordclouds/French_wordcloud.png',\n",
    "    'Italian': './wordclouds/Italian_wordcloud.png',\n",
    "    'Spanish': './wordclouds/Spanish_wordcloud.png',\n",
    "    'English': './wordclouds/English_wordcloud.png'\n",
    "}\n",
    "\n",
    "for language in languages:\n",
    "    # Drop the empty rows\n",
    "    target_dropped = remove_empty_rows(df, language)\n",
    "\n",
    "    # Combine all the text into a single string\n",
    "    long_string = \" \".join(target_dropped)\n",
    "\n",
    "    # Initialize the wordcloud\n",
    "    wc = WordCloud(background_color='white', contour_color='steelblue', height=600, width=800)\n",
    "\n",
    "    # Add data to the wordcloud\n",
    "    wc.generate(long_string)\n",
    "\n",
    "    # Save the cloud as a png file\n",
    "    wc.to_file(wordcloud_paths[language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize wordcloud\n",
    "# plt.imshow(wc, interpolation='bilinear')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    # Drop the empty rows\n",
    "    target_dropped = remove_empty_rows(df, language)\n",
    "\n",
    "    # Initialize counter vectorizer\n",
    "    vec = CountVectorizer()\n",
    "\n",
    "    # Transform to document term matrix\n",
    "    X = vec.fit_transform(target_dropped)\n",
    "\n",
    "    # Create DataFrame\n",
    "    tdm = pd.DataFrame(data=X.toarray(), columns=vec.get_feature_names_out())\n",
    "\n",
    "    # Sort DataFrame by word frequency\n",
    "    words = tdm.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "    words.to_csv(f'./data/common_words/{language}_common.csv', header=['count'], index_label='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13c2d661185228a4c4d63993c20c3e5bdf2ba4e265046529d225752df3d5e17"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
